{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the backpropagation learning algorithm using L2 regularization\n",
    "\n",
    "\n",
    "Implementing the backpropagation learning algorithm using L2 regularization for a network with one hidden layer and two hidden neurons.  The size of the input layer is also set to two. Initializing the weights by drawing from a Gaussian distribution centered around zero, and learning the weights for the XOR data:\n",
    "\n",
    "x1 = ( 1,-1,1,-1)\n",
    "\n",
    "x2 = ( 1,1,=1,-1)\n",
    "\n",
    "y = ( 1,0,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from theano import *\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output\n",
    "inp = np.array([[1,1],[-1,1],[1,-1],[-1,-1]])\n",
    "y = np.array ([[1],[0],[0],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initializing weights and biases\n",
    "w = np.random.randint(-2,2,size=(2,2))\n",
    "v = np.random.randint(-2,2,size=(2,1))\n",
    "b1 = np.random.randint(1,3,size=(2,1))\n",
    "b2 = np.random.randint(1,3,size=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for forward pass , takes biases and inputs and return output with output of hidden nodes.\n",
    "def forwardPass(w,v,b1,b2,x):\n",
    "    x=x.reshape((2,1))\n",
    "    temp=np.matmul(np.transpose(w),x)+b1\n",
    "    h=np.maximum(temp,0,temp)\n",
    "    y=np.matmul(np.transpose(v),h)+b2\n",
    "    return y,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE Loss calculation\n",
    "def loss(y,yhat):\n",
    "    return np.sum((y-yhat)*(y-yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "stepsize=0.009\n",
    "lambd = 0.001\n",
    "lossArr=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(epoch):\n",
    "    #start of epoch\n",
    "    for i in range(len(inp)):\n",
    "        #forwardpass\n",
    "        x=inp[i]\n",
    "        yhat,h=forwardPass(w,v,b1,b2,x)\n",
    "        #backward pass calculation\n",
    "        # dl/d(yhat)\n",
    "        one = (y[0] - yhat)\n",
    "        #update hidden output weights\n",
    "        v=v+stepsize*one*h.reshape((2,1))+lambd*v\n",
    "        #update output bias\n",
    "        b2=b2+stepsize*one\n",
    "        # find derivatives hidden nodes (relu) with respect to input\n",
    "        # to relu\n",
    "        h[h>0]=1\n",
    "        # dh/da ==> d(relu)/d(input to relu)\n",
    "        vtemp=np.multiply(h,v)\n",
    "        #update input weights\n",
    "        w=w+stepsize*one*np.matmul(x.reshape((2,1)),np.transpose(vtemp))+lambd*w\n",
    "        #update hidden nodes biases\n",
    "        b1=b1+stepsize*one\n",
    "        lossArr.append(loss(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = 100\n",
    "\n",
    "params = [w,v,b1,b2]\n",
    "def sgd(cost, params, lr=0.05):\n",
    "  grads = T.grad(cost=cost, wrt=params)\n",
    "  updates = []\n",
    "\n",
    "  for p, g in zip(params, grads):\n",
    "    updates.append([p, p - g * lr])\n",
    "\n",
    "  return updates\n",
    "\n",
    "updates = sgd(cost, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(inp)):\n",
    "    ynew,h=forwardPass(w,v,b1,b2,inp[i])\n",
    "    print (ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
